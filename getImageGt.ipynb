{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link nii files (image-gt pair) and create csv for tracing filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qeek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case2015.03.30.13.36.40\n",
      "case2015.03.30.13.36.40_CHIU_20150330_11527_002_1_21_CYBER_KNIFE.nii\n",
      "---\n",
      "case2012.08.29.15.19.35\n",
      "case2012.08.29.15.19.35_Lu_HungTu_7396_021_NTUH_Gating_3MM_OncoBody_Gated__80_0%_AMP.nii\n",
      "---\n",
      "case2016.11.04.13.51.39\n",
      "---\n",
      "case2016.11.04.13.54.03\n",
      "case2016.11.04.13.54.03_CHANG_20161104_1631_005_1_21_CYBER_KNIFE_C+.nii\n",
      "---\n",
      "case2009.03.04.13.16.54\n",
      "---\n",
      "case2011.04.18.13.08.02\n",
      "case2011.04.18.13.08.02_YANG_20110418_4663_002_1_21_CYBER_KNIFE.nii\n",
      "---\n",
      "case2015.06.16.13.40.29\n",
      "case2015.06.16.13.40.29_TSAI_20150616_16261_004_1_21_CYBER_KNIFE.nii\n",
      "---\n",
      "case2010.05.07.13.43.18\n",
      "case2010.05.07.13.43.18_GAU_20100507_43586_003_1_21_CYBER_KNIFE.nii\n",
      "---\n",
      "case2010.07.26.13.18.50\n",
      "case2010.07.26.13.18.50_SOUNG_20100726_46207_005_1_21_CYBER_KNIFE_C+.nii\n",
      "---\n",
      "case2011.01.18.13.31.24\n",
      "case2011.01.18.13.31.24_CHEN_20110118_1902_004_1_21_CYBER_KNIFE_C+.nii\n",
      "---\n",
      "case2012.08.29.15.17.39\n",
      "case2012.08.29.15.17.39_Lu_HungTu_7396_013_NTUH_Gating_3MM_OncoBody_Gated__0_0%_AMP.nii\n",
      "---\n",
      "case2010.02.08.11.30.30\n",
      "case2010.02.08.11.30.30_JANG_20100208_28496_003_CYBERKNIFE__2_AX_T1-2MM+C.nii\n",
      "---\n",
      "case2011.01.18.13.03.31\n",
      "case2011.01.18.13.03.31_CHEN_20110118_34619_004_0517349__AX_T1_+C.nii\n",
      "---\n",
      "case2015.03.30.13.37.46\n",
      "case2015.03.30.13.37.46_CHIU_20150330_11527_004_1_21_CYBER_KNIFE.nii\n",
      "---\n",
      "case2015.03.30.13.32.26\n",
      "---\n",
      "case2010.02.08.11.10.59\n",
      "case2010.02.08.11.10.59_JANG_20100208_28496_002_CYBERKNIFE_4_3D_FIESTA-AX.nii\n",
      "---\n",
      "case2011.01.18.13.27.12\n",
      "case2011.01.18.13.27.12_CHEN_20110118_1902_002_1_21_CYBER_KNIFE.nii\n",
      "---\n",
      "case2012.08.29.14.33.11\n",
      "case2012.08.29.14.33.11_Lu_HungTu_7396_002_NTUH_CyberKnife_1_5mm_OncoBody.nii\n",
      "---\n",
      "case2011.04.18.13.09.11\n",
      "---\n",
      "case2011.04.18.12.31.23\n",
      "case2011.04.18.12.31.23_YANG_20110418_36224_002_CYBERKNIFE__3D_FIESTA-C.nii\n",
      "---\n",
      "case2015.03.30.13.34.22\n",
      "---\n",
      "case2016.11.04.13.52.45\n",
      "case2016.11.04.13.52.45_CHANG_20161104_1631_002_1_21_CYBER_KNIFE.nii\n",
      "---\n",
      "case2009.03.04.13.18.10\n",
      "case2009.03.04.13.18.10_LO_20090304_29218_002_1_21_CYBER_KNIFE_C+.nii\n",
      "---\n",
      "case2011.01.18.12.58.13\n",
      "case2011.01.18.12.58.13_CHEN_20110118_34619_003_0517349__AX_T1.nii\n",
      "---\n",
      "case2016.11.04.13.49.17\n",
      "---\n",
      "case2011.04.18.13.30.56\n",
      "case2011.04.18.13.30.56_YANG_20110418_4663_006_1_24_CTA_+_Perfusion.nii\n",
      "---\n",
      "case2010.05.07.13.36.06\n",
      "case2010.05.07.13.36.06_GAU_20100507_43586_002_1_21_CYBER_KNIFE.nii\n",
      "---\n",
      "case2015.06.16.13.37.16\n",
      "---\n",
      "case2012.08.29.15.18.27\n",
      "case2012.08.29.15.18.27_Lu_HungTu_7396_018_NTUH_Gating_3MM_OncoBody_Gated__50_0%_AMP.nii\n",
      "---\n",
      "case2010.07.26.11.52.52\n",
      "---\n",
      "case2010.02.08.13.14.33\n",
      "case2010.02.08.13.14.33_JANG_20100208_40740_002_1_21_CYBER_KNIFE_C+.nii\n",
      "---\n",
      "case2015.06.16.13.38.05\n",
      "---\n",
      "case2015.06.16.13.39.24\n",
      "case2015.06.16.13.39.24_TSAI_20150616_16261_002_1_21_CYBER_KNIFE.nii\n",
      "---\n",
      "Total image-gt pair: 24\n"
     ]
    }
   ],
   "source": [
    "directory = '/run/user/1000/gvfs/smb-share:server=192.168.200.1,share=mri'\n",
    "files = os.listdir(os.path.join(directory, 'MRI'))\n",
    "imgList, gtList = [], []\n",
    "\n",
    "for f in files:\n",
    "    if f.endswith('.targets.nii'):\n",
    "        name = f[:-12]\n",
    "        print (name)\n",
    "        for nii in files:\n",
    "            if name in nii and not nii.endswith('.result.nii') and not nii.endswith('.targets.nii'):\n",
    "                print (nii)\n",
    "                imgList.append(nii)\n",
    "                gtList.append(f)\n",
    "        print ('---')\n",
    "    \n",
    "print ('Total image-gt pair: {}'.format(len(imgList)))\n",
    "df = pd.DataFrame({'image': imgList, 'target': gtList})\n",
    "df.to_csv(os.path.join(directory, 'MRI.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice nii file to original images and target images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "directory = '/run/user/1000/gvfs/smb-share:server=192.168.200.1,share=mri'\n",
    "image_directory = os.path.join(directory, 'postMRI', 'image')\n",
    "if not os.path.exists(image_directory):\n",
    "    os.makedirs(image_directory)\n",
    "target_directory = os.path.join(directory, 'postMRI', 'target')\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "# This is for 20180416 data(chest data are in delList)\n",
    "delList = [1 ,5, 8, 14, 20, 21]\n",
    "for i, f in enumerate(imgList):\n",
    "    if i not in delList:\n",
    "        # Get gt and image file \n",
    "        img_data = nib.load(os.path.join(directory, 'MRI', f)).get_data()\n",
    "        gt_data = nib.load(os.path.join(directory, 'MRI', gtList[i])).get_data()\n",
    "\n",
    "        # slice every row from top to bottom\n",
    "        for d in range(gt_data.shape[2]):\n",
    "            if gt_data[:, :, d].sum() > 0:\n",
    "                filename = '{:0>4d}_{:0>3d}.png'.format(i, d)\n",
    "                image = Image.fromarray(img_data[:, :, d]).convert('L')\n",
    "                image.save(os.path.join(image_directory, filename))\n",
    "                target = Image.fromarray(gt_data[:, :, d]).convert('L')\n",
    "                target.save(os.path.join(target_directory, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write target images to masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e2522f0098b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_data_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmisc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/rowanDL/ml-ntuh-001/dataloader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from dataloader import get_loader, get_data_path\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.misc as misc\n",
    "\n",
    "\n",
    "data_loader = get_loader()\n",
    "data_path = get_data_path()\n",
    "loader = data_loader(data_path, is_transform=True)\n",
    "\n",
    "directory = '/run/user/1000/gvfs/smb-share:server=192.168.200.1,share=mri'\n",
    "split = ['train', 'val']\n",
    "\n",
    "for s in split:\n",
    "    mask_directory = os.path.join(directory, 'postMRI', 'mask', s)\n",
    "    if not os.path.exists(mask_directory):\n",
    "        os.makedirs(mask_directory)\n",
    "        \n",
    "    files = os.listdir(os.path.join(directory, 'postMRI', 'target', s))\n",
    "    for f in files:\n",
    "        target = Image.open(os.path.join(directory, 'postMRI', 'target', s, f))\n",
    "        mask = loader.decode_segmap(np.asarray(target))\n",
    "        misc.imsave(os.path.join(mask_directory, f), mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply masks to original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "directory = '/run/user/1000/gvfs/smb-share:server=192.168.200.1,share=mri'\n",
    "split = ['train', 'val']\n",
    "\n",
    "for s in split:\n",
    "    map_directory = os.path.join(directory, 'postMRI', 'map', s)\n",
    "    if not os.path.exists(map_directory):\n",
    "        os.makedirs(map_directory)\n",
    "    \n",
    "    files = os.listdir(os.path.join(directory, 'postMRI', 'image', s))\n",
    "    for f in files:\n",
    "        bg = Image.open(os.path.join(directory, 'postMRI', 'image', s, f)).convert('RGB')\n",
    "        fg = Image.open(os.path.join(directory, 'postMRI', 'mask', s, f))\n",
    "        Image.blend(bg, fg, alpha=0.5).save(os.path.join(map_directory, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge masks and origin images side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "directory = '/run/user/1000/gvfs/smb-share:server=192.168.200.1,share=mri'\n",
    "split = ['train', 'val']\n",
    "\n",
    "for s in split:\n",
    "    filenames = os.listdir(os.path.join(directory, 'postMRI', 'image', s))\n",
    "    for f in filenames:\n",
    "        img1 = Image.open(os.path.join(directory, 'postMRI', 'image', s, f))\n",
    "        img2 = Image.open(os.path.join(directory, 'postMRI', 'map', s, f))\n",
    "        new = Image.new('RGB', (img1.size[0]*2+10, img1.size[1]), (255, 255, 255))\n",
    "        new.paste(img1, (0, 0))\n",
    "        new.paste(img2, (img1.size[0]+10, 0))\n",
    "        new.save(os.path.join(directory, 'postMRI', 'merge-image-map', s, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "directory = os.getcwd()\n",
    "\n",
    "filenames = os.listdir(os.path.join(directory, 'prediction', 'model_006_prediction', 'gt'))\n",
    "for f in filenames:\n",
    "    img1 = Image.open(os.path.join(directory, 'prediction', 'model_006_prediction', 'gt', f))\n",
    "    img2 = Image.open(os.path.join(directory, 'prediction', 'model_006_prediction', 'pred', f))\n",
    "    new = Image.new('RGB', (img1.size[0]*2+10, img1.size[1]), (255, 255, 255))\n",
    "    new.paste(img1, (0, 0))\n",
    "    new.paste(img2, (img1.size[0]+10, 0))\n",
    "    new.save(os.path.join(directory, 'prediction', 'model_006_prediction', 'merge', f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply sliding windows through images for retrieve proper train/val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sliding_window(image, step, windowSize):\n",
    "    image = np.asarray(image)\n",
    "    for y in range(0, image.shape[0], step):\n",
    "        for x in range(0, image.shape[1], step):\n",
    "            yield (x, y, image[y:y+windowSize[1], x:x+windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "directory = '/run/user/1000/gvfs/smb-share:server=192.168.200.1,share=mri'\n",
    "split = ['train', 'val']\n",
    "\n",
    "step = 20\n",
    "windowSize = (64, 64)\n",
    "for s in split:\n",
    "    win_img_directory = os.path.join(directory, 'postMRI', 'window_image', s)\n",
    "    if not os.path.exists(win_img_directory):\n",
    "        os.makedirs(win_img_directory)\n",
    "    \n",
    "    win_gt_directory = os.path.join(directory, 'postMRI', 'window_target', s)\n",
    "    if not os.path.exists(win_gt_directory):\n",
    "        os.makedirs(win_gt_directory)    \n",
    " \n",
    "    win_mask_directory = os.path.join(directory, 'postMRI', 'window_mask', s)\n",
    "    if not os.path.exists(win_mask_directory):\n",
    "        os.makedirs(win_mask_directory)\n",
    "        \n",
    "    files = os.listdir(os.path.join(directory, 'postMRI', 'target', s))\n",
    "    for f in files:\n",
    "        windowCount = 0\n",
    "        target = Image.open(os.path.join(directory, 'postMRI', 'target', s, f))\n",
    "        image = Image.open(os.path.join(directory, 'postMRI', 'image', s, f))\n",
    "        mask = Image.open(os.path.join(directory, 'postMRI', 'mask', s, f))\n",
    "\n",
    "        for (x, y, gt_patch) in sliding_window(target, step=step, windowSize=windowSize):\n",
    "            if gt_patch.sum() > 200:\n",
    "                filename = '{}_{:0>5d}.png'.format(f[:-4], windowCount)\n",
    "                gt_patch = Image.fromarray(gt_patch)\n",
    "                gt_patch.save(os.path.join(win_gt_directory, filename))\n",
    "                \n",
    "                image = np.asarray(image)\n",
    "                img_patch = image[y:y+windowSize[1], x:x+windowSize[0]]\n",
    "                img_patch = Image.fromarray(img_patch)\n",
    "                img_patch.save(os.path.join(win_img_directory, filename))\n",
    "      \n",
    "                mask = np.asarray(mask)\n",
    "                mask_patch = mask[y:y+windowSize[1], x:x+windowSize[0]]\n",
    "                mask_patch = Image.fromarray(mask_patch)\n",
    "                mask_patch.save(os.path.join(win_mask_directory, filename))\n",
    "                \n",
    "                windowCount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge gt and prediction masks side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "filenames = os.listdir(os.path.join(os.getcwd(), 'prediction', 'pred'))\n",
    "for f in filenames:\n",
    "    new = Image.new('RGB', (64*2+10, 64), (255, 255, 255))\n",
    "    img1 = Image.open(os.path.join(os.getcwd(), 'prediction', 'gt', f))\n",
    "    img2 = Image.open(os.path.join(os.getcwd(), 'prediction', 'pred', f))\n",
    "    new.paste(img1, (0, 0))\n",
    "    new.paste(img2, (64+10, 0))\n",
    "    new.save(os.path.join(os.getcwd(), 'prediction', 'merge', f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply window masks to original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "step = 20\n",
    "windowSize = (64, 64)\n",
    "\n",
    "filenames = os.listdir(os.path.join(os.getcwd(), 'prediction', 'image', 'val'))\n",
    "for f in filenames:\n",
    "    target = Image.open(os.path.join(os.getcwd(), 'prediction', 'target', 'val', f))\n",
    "    bg = Image.open(os.path.join(os.getcwd(), 'prediction', 'image', 'val', f)).convert('RGB')\n",
    "    fg = np.zeros((target.size[0], target.size[1], 3))\n",
    "    windowCount = 0\n",
    "    for (x, y, gt_patch) in sliding_window(target, step=step, windowSize=windowSize):\n",
    "        if gt_patch.sum() > 200:\n",
    "            window_filename = '{}_{:0>5d}.png'.format(f[:-4], windowCount)\n",
    "            fg[y:y+windowSize[1], x:x+windowSize[0]] += np.asarray(Image.open(os.path.join(os.getcwd(), 'prediction', 'pred', window_filename)))\n",
    "            windowCount += 1\n",
    "\n",
    "    fg = Image.fromarray(fg.astype(dtype=np.uint8))\n",
    "    Image.blend(bg, fg, alpha=0.5).save(os.path.join(os.getcwd(), 'prediction', 'pred-map', f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge gt and prediction masks side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "filenames = os.listdir(os.path.join(os.getcwd(), 'prediction', 'pred-map'))\n",
    "for f in filenames:\n",
    "    img1 = Image.open(os.path.join(os.getcwd(), 'prediction', 'map', 'val', f))\n",
    "    img2 = Image.open(os.path.join(os.getcwd(), 'prediction', 'pred-map', f))\n",
    "    new = Image.new('RGB', (img1.size[0]*2+10, img1.size[1]), (255, 255, 255))\n",
    "\n",
    "    new.paste(img1, (0, 0))\n",
    "    new.paste(img2, (img1.size[0]+10, 0))\n",
    "    new.save(os.path.join(os.getcwd(), 'prediction', 'merge-map', f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
